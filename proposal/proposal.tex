\documentclass[11pt]{article}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{latexsym}
\usepackage{algorithm,fullpage}
\usepackage{algpseudocode}
\usepackage{multirow}
\usepackage{url}
\usepackage{enumerate}
\usepackage{hyperref}

\usepackage[usenames,dvipsnames]{xcolor}
\hypersetup{colorlinks,breaklinks,
   linkcolor=BrickRed,urlcolor=Purple,
   anchorcolor=Blue,citecolor=NavyBlue,
  }

\title{\bf Predicting mental functions from brain activations}
\author{ Madhura Parikh \and Subhashini Venugopalan}

\begin{document}
\date{}
\maketitle

\section{Introduction}

Advances in neuroimaging techniques and rapid growth of scientific literature in neuroscience have made large improvements  in our understanding of human brain functions. 
Over the past few decades neuroscientists have studied brain images from EEG/MEG, fMRI and other sources to identify associations between psychological tasks and activity in brain regions~\cite{10.1371/journal.pcbi.1002707}.
Although these studies have led to large amounts of literature and several discoveries of bodily functions associated with certain brain regions (or networks) the mapping between functions to brain regions and vice-versa still remains largely unclear. In particular, different studies have associated the same regions to a wide range of functions~\cite{10.1371/journal.pcbi.1002707} and scientists believe that there could exist unique underlying functions that brain regions specialize in. 
%Another aspect of the study is to identify brain regions and networks that are get activated for a specific function.

\section{Problem Definition}
For the purposes of this project, we look at enhancing a new automated framework NeuroSynth~\cite{yarkoni2011large}  that combines text-mining and machine learning techniques to generate probabilistic mappings between cognitive and neural states. The framework addresses the following problems:
\begin{description}
\item[Forward Inference: ] In simple terms, given a psychological function or concept, the forward inference(a.k.a encoding) answers what regions of the brain are activated during that function. e.g. pain, vision, conflict, etc
\item[Reverse Inference: ] The reverse inference(a.k.a. decoding) looks at the reverse mapping. i.e. Given a signature of neural activity, reverse inference identifies the cognitive state(s) and functions that the activations correspond to.
\end{description}
Both forward and reverse inference problems are quite challenging. However, forward inference has been studied well in medical literature and appears to not be of as much interest to the medical community since, neuroimaging techniques provide an easy way to verify the associations. On the other hand, reverse inference, which seems to be of greater interest to the community is also a more challenging (difficult) problem since multiple cognitive states could have very similar neural signatures~\cite{yarkoni2011large}. In this project we therefore focus on the latter problem,  and propose to use \emph{transfer-learning} as a part of our solution.  We also describe an approach for forward inference with out of vocabulary terms, as a possible future extension.

\subsection{Related Work}
%Explain bits from Neurosynth paper and Sanmi's other paper here.
There are several approaches in contemporary literature that have addressed the forward and reverse inference problems as described above. However most of these approaches have been limited to manual efforts by individual research groups, thereby failing to scale up with the increasing availability of fMRI data. Recent works like~\cite{yarkoni2011large, sanmi2013multi} have therefore attempted to build automated frameworks for these tasks using machine learning and statistical techniques.  In ~\cite{yarkoni2011large}, the authors use a very simple model for both forward and reverse inference. Using some $3000$ odd fMRI studies, they characterize each study by $2$ feature vectors - \textbf{Activation vector ($A_i$)} and \textbf{Term Vector ($T_i$)}.  $A_i$ is a binary vector with $\approx 10^6$ features, a particular feature is set to $1$ if the study reports that voxel to be activated and $0$ otherwise. Additional pre-processing is carried out to ensure that the $3D$ coordinates that appear in the document are mapped smoothly to the voxels. $T_i$  is a vector of length $\approx 10^4$, each feature indicating whether the corresponding term of interest appears above a pre-defined cut-off frequency in the document or not. 

The forward inference i.e $\Pr[A \vert T] $was approximated using a simple frequency count with smoothing (i.e it was set to be the ratio of the number of times a term and activation point appeared together in a document, to the total  number of occurrences of the term in the document, assuming that the terms had a uniform prior). For the reverse inference,  a Naive Bayes approach was used by assuming that each of the activation points were independent and by applying the Bayes rule to the calculated forward inference probabilities. The Naive Bayes classifier was trained as a binary classifier (predicting which of the two given terms was the likely class label) as well as a multiclass classifier, considering sets of upto $10$ terms (since considering all the $10^4$ terms for presence/absence would result in an exponential blow-up). While both the feature extraction as well as the models used in this work are very simplistic, the results they obtain are very promising. 

There have been other approaches that have further built on NeuroSynth. For instance in ~\cite{sanmi2013multi}, the authors use label decomposition techniques in a one-vs-all setting to predict multiclass labels for the reverse inference problem. They use Support Vector Machines ($l_2$ regularized), logistic regression and ridge classifier for these tasks,  comparing the outcomes based on different criteria like precision, recall and Hamming loss, to show that the multiclass approach is effective for reverse inference. They also propose to use other multiclass approaches and regularization techniques and analyze their performance as future work. 

In another similar work~\cite{schwartz2013mapping} uses a Generalized Linear Model(GLM) for forward inference. For the reverse inference they use logistic regression with Ward clustering to counter the high dimensionality of the problem. 




%[Insert these in between appropriately or keep it as a para in itself]
%While Neurosynth addresses both the forward and reverse inference, . 
%[Explain forward inference Pr()]. Address removal of domain specific stopwords. For the reverse inference, they leverage the forward inference study and use a Naive Bayes classifier to infer the probability of the cognitive state given the activation. 

\section{Proposed Work}

Our project aims to primarily address the reverse inference task. We propose to more sophisticated algorithms to solve the classification problem currently addressed by the Naive Bayes classifier. Additionally, we plan to use techniques from transfer learning to determine the concept from the brain activations (and images) collectively. In addition, time permitting, we propose ``zero-shot" forward inference for unseen concepts. i.e. Given a new concept for which we have not seen brain activation points, we hope to predict the activation network. A rough outline of our ideas to achieve this goal are mentioned below:

\begin{enumerate}

    \item {\bf Reverse Inference via more sophisticated classification techniques.} Currently NeuroSynth is available as an open source tool for the benefit of the neuroscience community. At its core, though it still uses the simple models that were introduced in~\cite{yarkoni2011large} such as Naive Bayes classification. While there have been other approaches that have used more powerful models, they have not been implemented concretely as open source tools. We propose to use a combination of logistic regression with hierarchical clustering and integrate these approaches to the current NeuroSynth framework. While we start with logistic regression as a simple yet reasonable model, we will be flexible in our approach and switch to a different model such as Support Vector Machines, if our experiments indicate it to be more promising. We also propose to use hierarchical clustering as a means of reducing the high dimensionality of the problem. By using hierarchical clustering we hope to reduce the large number($\approx 10^6$) of activation points to a more manageable size while at the same time not losing too much information, that may render our labels too general to be of much interest to neuroscientists.

    \item {\bf Reverse inference transfer learning.} A very interesting extension to NeuroSynth would be to make it possible to infer concepts given raw fMRI images. Currently NeuroSynth works only on binarized images (i.e images are thresholded so that voxels of sufficient activation are set to $1$ and the rest are set to $0$). However there are a vast number of real fMRI images that would be hugely benefitted by the various inference tools in NeuroSynth if they could be analyzed directly. This would require to do transfer learning where the source and destination have different domains but the same target.~\cite{pan2010survey,taylor2009transfer} is a concise survey of existing transfer learning approaches. We propose to use some form of transductive transfer learning that enables us to make reasonable predictions even in the space of real images. We propose to use various co-clustering techniques as a first step towards this. Various such techniques like \emph{Self Taught Clustering(STC )} ~\cite{dai2008self} and \emph{Transfer Spectral Clustering}~\cite{jiang2012transfer} are some examples.

    \item {\bf Zero-shot forward inference.}
 (Time permitting)  Given a new concept we would like to predict the brain activation points for this unseen concept. In order to do this, we plan to leverage contextual meaning of the context from text documents. We plan to represent each context in a distributional vector space constructed based on word co-occurrence statistics in neuroscience literature. These vectors give us a way of measuring similarity between two concepts in literature. ow, given a new concept, we can then identify the concepts/functions that are most similar and report the activation points that lie in their intersection.

\end{enumerate}

\section{Data Source}
We intend to use OpenfMRI~\cite{poldrack2013toward} as a source of raw fMRI images at the subject level. Apart from this we will also work with NeuroVault\footnote{\url{http://neurovault.org}} data for fMRI images at the group level. NeuroSynth itself has an excellent repository of $8000$ odd scientific papers that will aid us in the text-mining relevant sections of the project. All the data is open source and freely available via a convenient API. 

\small
\bibliographystyle{plain}
\nocite{*}
\bibliography{proposal.bib}

\end{document}


